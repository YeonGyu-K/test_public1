{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlbRU9Y0W8t0+aZVdSDrYL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ygkim77/Korea_Univ/blob/main/Group_Quiz_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group Quiz 1"
      ],
      "metadata": {
        "id": "EQLiDyqTH8BL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "bZacXQ3FfJ2v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decorator\n",
        "import time\n",
        "def timer(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        computation_time = end_time - start_time\n",
        "        print(f\"Execution time of {func.__name__}: {computation_time} seconds\")\n",
        "        return result\n",
        "    return wrapper"
      ],
      "metadata": {
        "id": "CKlVXhj43shz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_b = 1\n",
        "true_w = 2\n",
        "N = 100 # number of data\n",
        "\n",
        "np.random.seed(42)\n",
        "x = np.random.rand(N, 1)\n",
        "epsilon = (0.1 * np.random.randn(N, 1)) # normal distribution\n",
        "y = true_b + true_w * x + epsilon # data generation"
      ],
      "metadata": {
        "id": "TlJY4V6-M6AM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffles the indices\n",
        "idx = np.arange(N)\n",
        "split_index = int(N * 0.8) # train-validation split\n",
        "\n",
        "train_idx = idx[:split_index]\n",
        "val_idx = idx[split_index:]\n",
        "\n",
        "# Generates train and validation sets: it can be replaced by \"train_test_split\"\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_val, y_val = x[val_idx], y[val_idx]"
      ],
      "metadata": {
        "id": "ZwhfA2uINAKk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# create tensor at GPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "x_train_tensor = torch.as_tensor(x_train).to(device)\n",
        "y_train_tensor = torch.as_tensor(y_train).to(device)"
      ],
      "metadata": {
        "id": "8FUA9c8bNGkG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "@timer\n",
        "def train_model_torch_optim(lr=0.1, epochs=1000):\n",
        "    # Initialize parameters\n",
        "    b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    parameters = [b, w]\n",
        "    optimizer = optim.SGD(parameters, lr=lr)\n",
        "    mse_loss = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Loss computation\n",
        "        y_hat = b + w * x_train_tensor\n",
        "        loss = mse_loss(y_hat, y_train_tensor)\n",
        "\n",
        "        # Standard PyTorch code for training(Gradient computation and descent)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    return b, w"
      ],
      "metadata": {
        "id": "nYyXwl7sNOmq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b_hat, w_hat = train_model_torch_optim()\n",
        "print(\"b_estimate: {}, w_estimate: {}\".format(b_hat, w_hat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTFsWFe3NPN2",
        "outputId": "8050f4e6-73a6-44ff-dae7-1cc766a8b025"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time of train_model_torch_optim: 0.39243054389953613 seconds\n",
            "b_estimate: tensor([1.0234], requires_grad=True), w_estimate: tensor([1.9368], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "x_test_tensor = torch.as_tensor(x_val).to(device)\n",
        "y_test_tensor = torch.as_tensor(y_val).to(device)"
      ],
      "metadata": {
        "id": "nVcicjQeNnrt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = b_hat + w_hat * x_test_tensor\n",
        "mse_loss = nn.MSELoss()\n",
        "loss = mse_loss(y_hat, y_test_tensor)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iez2V7wBNnuc",
        "outputId": "1dc4ab61-973e-4247-f6a0-9231812c59c5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0098, dtype=torch.float64, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group Quiz 2"
      ],
      "metadata": {
        "id": "Of_fVgEnOyUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/KUBIG/2023_summer/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRt9E_ooIcS8",
        "outputId": "bc7f71b0-25ef-415a-cf48-2ecb4290c303"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('quiz_data.pkl', 'rb') as f:\n",
        "    loaded_dict = pickle.load(f)"
      ],
      "metadata": {
        "id": "GNUN5TfSHIQi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = loaded_dict['x']\n",
        "y = loaded_dict['y']"
      ],
      "metadata": {
        "id": "z95bjARQH-M1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZnRmTJMH-O3",
        "outputId": "9e62d6ea-4d12-4b07-8be2-0103708f239d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqjU4HrSLUIz",
        "outputId": "a406f926-a275-427f-c393-adfae9636f8a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = len(x)\n",
        "idx = np.arange(N)\n",
        "split_index = int(N * 0.8)\n",
        "\n",
        "train_idx = idx[:split_index]\n",
        "val_idx = idx[split_index:]\n",
        "\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_val, y_val = x[val_idx], y[val_idx]"
      ],
      "metadata": {
        "id": "Ch6Ecvt-H-Un"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create tensor at GPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "x_train_tensor = torch.as_tensor(x_train).to(device)\n",
        "y_train_tensor = torch.as_tensor(y_train).to(device)"
      ],
      "metadata": {
        "id": "O2d3IascH-Xo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "@timer\n",
        "def train_model_torch_optim(lr=0.1, epochs=1000):\n",
        "    # Initialize parameters\n",
        "    b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    w3 = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    w5 = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    parameters = [b, w, w3, w5]\n",
        "    optimizer = optim.SGD(parameters, lr=lr)\n",
        "    mse_loss = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Loss computation\n",
        "        y_hat = b + w * x_train_tensor + w3 * (x_train_tensor**3) + w5 * (x_train_tensor**5)\n",
        "        loss = mse_loss(y_hat, y_train_tensor)\n",
        "\n",
        "        # Standard PyTorch code for training(Gradient computation and descent)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    return b, w, w3, w5"
      ],
      "metadata": {
        "id": "PrmchspDX9Wy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "x_test_tensor = torch.as_tensor(x_val).to(device)\n",
        "y_test_tensor = torch.as_tensor(y_val).to(device)"
      ],
      "metadata": {
        "id": "MPNr7YHtdkpf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b_hat, w_hat, w3_hat, w5_hat = train_model_torch_optim()\n",
        "print(\"b_estimate: {}, w_estimate: {}, w3_estimate: {}, w5_estimate: {}\".format(b_hat, w_hat, w3_hat, w5_hat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nav_71A6YK23",
        "outputId": "84d6722f-0f31-4bfc-f775-5e428efced4b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time of train_model_torch_optim: 0.4185976982116699 seconds\n",
            "b_estimate: tensor([-0.7630], requires_grad=True), w_estimate: tensor([2.1463], requires_grad=True), w3_estimate: tensor([-2.4847], requires_grad=True), w5_estimate: tensor([-0.2150], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = b_hat + w_hat * x_test_tensor + w3_hat * (x_test_tensor**3) + w5_hat * (x_test_tensor**5)\n",
        "mse_loss = nn.MSELoss()\n",
        "loss = mse_loss(y_hat, y_test_tensor)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NAFl89Vdkvv",
        "outputId": "cf277dc9-b1bd-40cf-e644-40b1a092e5d4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}